# src/utils.py
"""
Utils limpo e focado em helpers (sem treino de modelo).
Cont√©m:
 - load_data: carregar CSV
 - basic_clean: limpeza leve e remo√ß√£o de id
 - get_features_target: separar X e y
 - split_data: train_test_split com stratify (se aplic√°vel)
 - evaluate_model: gerar m√©tricas (usa y_true e y_pred)
 - save_artifact / load_artifact: salvar / carregar dict {pipeline, threshold, metadata}
 - predict_from_raw: utilit√°rio para infer√™ncia usando payload bruto + reference_df
"""

import os
import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from typing import Tuple, Optional, Dict, Any


# ----------------------------
# I/O e limpeza simples
# ----------------------------
def load_data(path: str) -> pd.DataFrame:
    """
    Carrega CSV em um DataFrame.
    """
    return pd.read_csv(path)


def basic_clean(df: pd.DataFrame, drop_id: bool = True) -> pd.DataFrame:
    """
    Limpeza simples:
      - remove linhas completamente nulas
      - remove coluna 'id' se existir (opcional)
      - retorna c√≥pia limpa
    NOTA: n√£o faz encoding/escalonamento ‚Äî isso deve ser feito pelo pipeline salvo.
    """
    if not isinstance(df, pd.DataFrame):
        raise ValueError("basic_clean espera um pandas.DataFrame")
    df_clean = df.dropna(how="all").copy()
    if drop_id and "id" in df_clean.columns:
        df_clean = df_clean.drop(columns=["id"])
    return df_clean


def get_features_target(df: pd.DataFrame, target: str = "stroke") -> Tuple[pd.DataFrame, pd.Series]:
    """
    Separa X e y. Lan√ßa erro se target n√£o existir.
    """
    if not isinstance(df, pd.DataFrame):
        raise ValueError("get_features_target espera um pandas.DataFrame")
    if target not in df.columns:
        raise ValueError(f"Target '{target}' n√£o encontrado no DataFrame.")
    X = df.drop(columns=[target]).copy()
    y = df[target].copy()
    return X, y


def split_data(df: pd.DataFrame, target: str = "stroke", test_size: float = 0.2,
               random_state: int = 42, stratify: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    Faz train_test_split retornando X_train, X_test, y_train, y_test.
    Usa stratify por padr√£o (recomendado para problemas desbalanceados).
    """
    X, y = get_features_target(df, target=target)
    strat = y if stratify else None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=strat
    )
    return X_train, X_test, y_train, y_test


# ----------------------------
# Avalia√ß√£o
# ----------------------------
def evaluate_model(y_true, y_pred) -> Dict[str, float]:
    """
    Calcula m√©tricas b√°sicas e imprime relat√≥rio.
    Retorna dicion√°rio com as m√©tricas chaves.
    """
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)

    print(f"üéØ Acur√°cia: {acc:.4f}")
    print(f"Precision (classe positiva): {prec:.4f}")
    print(f"Recall (classe positiva): {rec:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("\nüìã Relat√≥rio de classifica√ß√£o:")
    print(classification_report(y_true, y_pred))

    return {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1}


# ----------------------------
# Artifact helper (pipeline + threshold + metadata)
# ----------------------------
def save_artifact(pipeline_obj, threshold: float = 0.492, path: str = "./models/artifact_stroke.pkl",
                  metadata: Optional[Dict[str, Any]] = None) -> None:
    """
    Salva um dict contendo:
      {"pipeline": pipeline_obj, "threshold": <float>, "metadata": <dict opcional>}
    Cria diret√≥rio se necess√°rio.
    """
    os.makedirs(os.path.dirname(path), exist_ok=True)
    artifact = {"pipeline": pipeline_obj, "threshold": float(threshold)}
    if metadata is not None:
        artifact["metadata"] = metadata
    joblib.dump(artifact, path)
    print(f"‚úî Artifact salvo em: {path}")


def load_artifact(path: str = "./models/artifact_stroke.pkl"):
    """
    Carrega e retorna o conte√∫do do artifact (dict ou pipeline direto).
    Lan√ßa FileNotFoundError se n√£o existir.
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"Artifact n√£o encontrado em: {path}")
    return joblib.load(path)


# ----------------------------
# Infer√™ncia a partir de payload bruto
# ----------------------------
def predict_from_raw(artifact_or_model, payload_json: dict, reference_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Faz predi√ß√£o a partir de um payload bruto (dicion√°rio), usando prepare_input_dataframe
    para alinhar as colunas com reference_df.

    artifact_or_model: pode ser:
      - dict com 'pipeline' e opcional 'threshold' (artifact salvo)
      - pipeline/estimator diretamente (ex.: carregado com joblib.load)
    payload_json: dicion√°rio com campos brutos (igual ao payload da API)
    reference_df: DataFrame de refer√™ncia (mesma estrutura usada no treino) ‚Äî necess√°rio para alinhar colunas

    Retorna:
      {"prediction": int(0|1), "probability": float|None, "threshold_used": float|None}
    """
    # import local para evitar depend√™ncia circular em m√≥dulos que importam utils
    from src.preprocess import prepare_input_dataframe

    # valida√ß√µes iniciais
    if not isinstance(payload_json, dict):
        raise ValueError("payload_json deve ser um dicion√°rio (JSON-like).")
    if not isinstance(reference_df, pd.DataFrame):
        raise ValueError("reference_df deve ser um pandas.DataFrame (o dataframe de refer√™ncia do treino).")

    # determinar model e threshold de forma segura
    if isinstance(artifact_or_model, dict):
        if "pipeline" not in artifact_or_model:
            raise ValueError("artifact dict deve conter a chave 'pipeline'.")
        model = artifact_or_model["pipeline"]
        threshold = artifact_or_model.get("threshold", None)
        threshold = float(threshold) if threshold is not None else None
    elif hasattr(artifact_or_model, "predict"):
        model = artifact_or_model
        threshold = None
    else:
        raise ValueError("artifact_or_model inv√°lido: deve ser um dict com 'pipeline' ou um model com m√©todo predict.")

    # alinhar o payload com as colunas do reference_df (sem transformar)
    input_df = prepare_input_dataframe(payload_json, reference_df)

    result = {"prediction": None, "probability": None, "threshold_used": threshold}

    # tentar predict_proba -> se n√£o suportar, fallback para predict
    try:
        proba_arr = model.predict_proba(input_df)
        # assumir que a coluna 1 √© a prob da classe positiva
        if proba_arr is None:
            raise RuntimeError("model.predict_proba retornou None")
        if proba_arr.ndim != 2:
            raise RuntimeError(f"predict_proba retornou array com shape inesperado: {proba_arr.shape}")
        if proba_arr.shape[1] == 1:
            prob_pos = float(proba_arr[0][0])
        else:
            prob_pos = float(proba_arr[0][1])
        result["probability"] = prob_pos
        if threshold is not None:
            result["prediction"] = int(prob_pos >= float(threshold))
        else:
            # sem threshold, usar a decis√£o direta do classificador
            result["prediction"] = int(model.predict(input_df)[0])
    except Exception as e_proba:
        # fallback: tentar predict direto e reportar erro original para debug
        try:
            pred = int(model.predict(input_df)[0])
            result["prediction"] = pred
            result["probability"] = None
            result["threshold_used"] = threshold
            # anexar informa√ß√£o de debug (n√£o obrigat√≥rio)
            result["_warning"] = f"predict_proba falhou: {e_proba}; usado predict() como fallback."
        except Exception as e_pred:
            raise RuntimeError(f"Falha ao predizer: predict_proba erro: {e_proba}; fallback predict erro: {e_pred}")

    return result
